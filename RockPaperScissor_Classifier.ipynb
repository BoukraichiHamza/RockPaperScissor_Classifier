{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "21\n",
      "202\n"
     ]
    }
   ],
   "source": [
    "transf = transforms.Compose([transforms.Grayscale(),transforms.ToTensor()])\n",
    "dataset = datasets.ImageFolder('PPC2/.',transf)\n",
    "n = len(dataset)\n",
    "\n",
    "ntrain = int(0.9 *n)\n",
    "ntest = n - ntrain\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [ntrain, ntest])\n",
    "nbatch = 10\n",
    "print (ntrain)\n",
    "print (ntest)\n",
    "print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataload_train = dict(shuffle=True, batch_size=nbatch,num_workers=0, pin_memory=True)\n",
    "train_load = dataloader.DataLoader(train_data, **dataload_train)\n",
    "\n",
    "dataload_test = dict(shuffle=True, batch_size=ntest,num_workers=0, pin_memory=True)\n",
    "test_load = dataloader.DataLoader(test_data, **dataload_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hidden Layer NN\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc0 = nn.Linear(32 * 32, 128*128)\n",
    "        #self.fc1 = nn.Linear(64*64, 32*32)\n",
    "        #self.fc2 = nn.Linear(32*32, 16*16)\n",
    "        self.fcout = nn.Linear(128*128,3)\n",
    "    def forward(self, x):\n",
    "        out = self.fc0(x.view(-1,32*32))\n",
    "        out = F.sigmoid(out)\n",
    "        #out = F.tanh(self.fc1(out))\n",
    "        #out = F.tanh(self.fc2(out))\n",
    "        out = F.sigmoid(self.fcout(out))\n",
    "        return F.log_softmax(out, dim=0)    \n",
    "    \n",
    "    \n",
    "model = Model()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "optimizer = optim.Adagrad(model.parameters())\n",
    "\n",
    "EPOCHS = 20\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [1/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [2/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [3/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [4/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [5/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [6/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [7/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [8/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [9/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [10/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [12/19], Loss: 1.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [11/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [12/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [13/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [14/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [15/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [16/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [17/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [18/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [19/20], Step [19/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [1/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [2/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [3/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [4/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [5/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [6/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [7/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [8/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [9/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [10/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [11/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [12/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [13/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [14/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [15/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [16/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [17/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [18/19], Loss: 1.0986\n",
      "Epoch [20/20], Step [19/19], Loss: 1.0986\n",
      "Test Accuracy of the model on the test images: 23.80952380952381 %\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_load)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_load):\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "model.eval()  # eval mode\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_load:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f94bc08c9b0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
